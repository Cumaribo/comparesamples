# This code is used to download all the forest- no forest binary masks from the 
# Global forest cover Dataset by Hansen et al  using the package ForestChange.
#It  returns maps for each one of the thresholds between 70 and 100%. The next step is to load this, stack cut it by pieces and then carry out the comparson betwee nthe maps. Everything trough maps.
#It requires the package "greenbrown" available here:
http://greenbrown.r-forge.r-project.org
# Load libraries 
rm(list=ls())



install.packages('unixtools', repos = 'http://www.rforge.net/')

unixtools::set.tempdir('/media/mnt/Ecosistemas_Colombia/tempfiledir')

tempdir()
library(raster)
library(rgdal)
library(forestChange)
library(parallel)
library(sf)
library(tidyverse)
library(purrr)
library(furrr)

dir.create('tempfiledir')
tempdir=paste(getwd(),'tempfiledir', sep="/")
rasterOptions(tmpdir=tempdir)
#Set your working folder
setwd("/media/mnt/Ecosistemas_Colombia")
dir()

# load data 
# mun <- st_read('/media/mnt/Ecosistemas_Colombia/ContornoColombia.geojson')
# mun <- mun[!st_is_empty(mun),,drop=FALSE]

#make sure that your vectorfile is in crs=WGS84, as this is the one of the gobal forest dataset.

# if necessary, use this to reproject:
#mun <- spTransform(mun, crs='+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0')

Sys.setlocale(locale="C")

# # convert map into spatial polygon dataframe.
# mun <- as(mun, 'Spatial')
# 
# # create vector withe the threshold you want to iterate. 
# # Warning, this process requires a lot of temp memory, so make sure to have enough storage space or split your process in smaller chuncks
# perc2 <- 70:100
# # this creates a vector of names from the vector
# perccar <- as.character(perc2) 
# # set a temporary working folder.

# 
# # download each one of the maps. The allowable length of your vector depends on your available storage and the size of the study area 
# # i need to parallelize this. It is not running parallel when it comes to "Mosaicing is required"
# test2 <- map(perc2, function(x) FCMask(mun, year=2017, cummask=FALSE, perc = x, mc.cores = 8)) 
# 
# #Save your rasters
# # parallelize this, to get it to write faster into memory
# map(1:length(perc2), function(x) writeRaster(test2[[x]], paste('forest_col', perccar[x], sep='_'), format='GTiff')) 

rm(list=ls())
#load the biomas

mun <- st_read('/media/mnt/Ecosistemas_Colombia/biomas_wgs84.shp')
labels <- (mun$BIOMA_IAvH)

mun <- as(mun, 'Spatial')
# split mun into list of independent polygons  
biomat <- mun%>%split(.$BIOMA_IAvH)

#######################################################################################################
biomat <- biomat[-c(1:379)]
biomat[[1]]
#load the rasters i just created. 
#create a list with the names of the masks
listr <- list.files(".", "forest_col")
#create an empty container list
r.list <- list()

# load the rasters
for(i in 1:length(listr)){
  r.list[[i]] <- raster(listr[i])}
# stack the rasters to build a multi band rasterstack. 
stack_forests <- do.call(stack, r.list)
rm(r.list)
# I should have done this here, but I missed it and can't repeat a procedure that took a whole week to run
# stack_forests[is.na(stack_forests)] <- 0
# stack_forests <- mask(stack_forests, mun)

#this is the next step. 
#Get to mask over all of the 399 pieces. 
#get the names
# attention, for memoy reasons, I had to split the thing in several stages, and thats why it. DON;'T FORGET to adjust this!!!!!!!!!!!!!
names <- as.list(mun$BIOMA_IAvH)
names <- map(1:length(names), function(x) as.character(names[[x]]))
namesu <- unlist(names)
namesu <- namesu[379:386]
dir()
#Let us start small
tempdir()
tmpDir()
#crop using the ecxtent of each bioma
#here i will have a set of multiband rasters for each of the biomas
#next step ->save the data

#prepare the cores. I am testing the furrr package to parallelize in a tidyverse map. My problem now is that the desktop at the lab has a tiny hard drive, and for some reason
# install.packages('unixtools', repos = 'http://www.rforge.net/'), 
# unixtools::set.tempdir('/media/mnt/Ecosistemas_Colombia/tempfiledir') and
# dir.create('tempfiledir')
# tempdir=paste(getwd(),'tempfiledir', sep="/")
# rasterOptions(tmpdir=tempdir)

#still dont send the stuff to process in nimbus, but keeps woking on the local machine. I decided to split it un parts for the moment

plan(multisession, workers=7)

  cropped <- future_map(1:length(namesu), function(x) crop(stack_forests, extent(biomat[[x]])))
  maskedt <- map(1:length(cropped), function(x) raster::mask(cropped[[x]], biomat[[x]]))
  future_map(1:length(maskedt), function(x) writeRaster(maskedt[[x]], paste('forests_2017', namesu[x], sep='_'), format='GTiff', overwrite=TRUE)) 

#########################################################################################################################

#Keep this in mind, it will be useful when performing the anaysis
#test the original function. There is something going on with the years 2016:2018 but i need this to run
# for the moment

# What do I have?
#   
#   1. 399 polygons (biomas IAVH)
#   2. 2017 Raster Bosques
#   2. 2016 Raster Bosques
#   4. FCMask function 


#Need to:

#Download all the masks for all the biomas for all the threshols for 2017!!!! 
# will i get a dataset for all places iterating over all thresholds! and this will be evaluated with compareraster. I need a list with all the thresholds for each one of the places
#create binary forest mask with forestChange 
# you can plot any just to check. not required
dir()
listr <- list.files(".", "forests_2017")

#create an empty container list
r.list <- list()
#load the stacks110
for(i in 1:length(listr)){
  r.list[[i]] <- stack(listr[i])}

#this just loads the first band, it is done to extract the names! Next time get rid of spaces sand tildes] I already have the names, i fdont need them again!
# r.list2 <- list()
# #load the stacks
# for(i in 1:length(listr)){
#   r.list2[[i]] <- raster(listr[i])}
# 
# # #create the list with the names 
# listnames <- list()
# for(i in 1:length(r.list)){
#   listnames[i] <- substr(r.list2[[i]]@file@name, 46, nchar(r.list2[[i]]@file@name))}
# listnames <- unlist(listnames)
# listnames <- as.factor(listnames)
# #i dont' need this anymore, so wewill get rid of it 
# rm(r.list2)

listnames



# set your future settings (number of cores and memory to be allocated)
mem_future <- 1000*1024^2 #this is toset the limit to 1GB
plan(multisession, workers=7)
options(future.globals.maxSize= mem_future)
# this function subsitutes the NA for zeros, masks the rasters and writes the new raster
masker <- function(test,poly, labels){
  test <- map(1:nlayers(test), function(x) replace_na(test[[x]],0))
  print('na-replaced')
  test2 <- do.call(stack,test)
  print('stacked')
  test2 <- mask(test2, poly)
  print('masked, writing raster')
  writeRaster(test2, paste('masked', labels, sep='_'), format='GTiff')
  return(test2)}


test2 <- future_map(1:length(names), function(x) masker(r.list[[x]], biomat[[x]], labels[x]))

test2 <- future_map(1:2, function(x) masker(r.list[[x]], biomat[[x]], labels[x]))


rm(r.list)



# mask to your study area
r.list <- (x=1:length(years))%>%map(function(x) mask(forests[[x]], mun))


# compare each pair of years. 



compare1 <- CompareClassification(forests[[1]], forests[[2]], 
                                  names = list('year n'=c('no-Forest','forest'),'year n+1'=c('no-Forest','forest')), samplefrac = 1)

#you could try to map this function too. Else, you will have to run each step manually, changing the index for each forests Argument. 


#of course, you can run a comparison between any given pair of years for your study period, they donÂ´t need to be consecutive. 
#CompareClassification produces a list with three objects.
# 1. A raster with the changes. The pixel values range from  1 to 4; 1. stands for class 1 that remained the same, 2 and 3 changes 
# in one way or another and 4 is class two remained the same. Yo can export it with writeraster
# 2. A square contingency table that tells you the difference between the pair of maps numerically. it's like a confusion matrix
# but it discloses the level of agreemwnt between both maps and how many pixles were gsined/lost for each class.
# The kappa bwtween the two maps. It is supposed to represent the overall level of agreement between the two maps.
# however, as it does not tell where these pixels are, or to which class they belong, some authors do not recommend using it
# for more information, check https://www.researchgate.net/profile/Marco_Millones/publication/233196329_Death_to_Kappa_Birth_of_quantity_disagreement_and_allocation_disagreement_for_accuracy_assessment/links/0deec531e1ea538616000000.pdf

plot(compare1)
#this plots an agrerement map between each pai of maps, showing what pixels remained the same, and for the ones that changed
# the type of change (forest to no-forest; a forest loss or no-forest to forest, a forest gain). You can export it as a .tiff or png or 
#whatever you pre
